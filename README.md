# **Boas vindas ao Flow of Cash!**

Para executar o script, observe as orienta√ß√µes descritas a seguir, e se tiver qualquer d√∫vida, sugest√£o, contribui√ß√£o, considere abrir uma issue ou entrar em contato. üöÄ

O objetivo √© testar o .NET no Apache Spark atrav√©s de um aplicativo de console, com um exemplo de leitura e tratamento simples de arquivo parquet utilizando o C# como linguagem.


# Orienta√ß√µes


<details>
  <summary><strong>Estrutura das pastas</strong></summary><br />

  O diret√≥rio [**Code**](Code) tem um arquivo com o exemplo das depend√™ncias necess√°rias (arquivo FlowOfCash.csproj) e c√≥digo do tratamento do arquivo parquet (arquivo Program.cs) que ser√° utilizado como explicado na se√ß√£o **_Como executar o c√≥digo_**

  E o diret√≥rio [**sample-generator**](sample-generator) tem o c√≥digo python utilizado para cria√ß√£o dos arquivos parquet usados como exemplo, bem como a amostra em si.

  Por ser uma solu√ß√£o de big data, sinta-se √° vontade para gerar novos arquivos √† partir dele para explorar o Spark agregado ao .NET.

---

  <br/>
</details>



<details>
  <summary><strong>Pr√© requisitos</strong></summary><br />

  O ambiente para execu√ß√£o do c√≥digo requer as seguintes ferramentas:

  * **.Net**

  * **Java**

  * **Apache Spark**

  * **Microsoft.Spark.Worker**

  [Essa documenta√ß√£o](https://learn.microsoft.com/pt-br/previous-versions/dotnet/spark/tutorials/get-started?tabs=linux&WT.mc_id=dotnet-35129-website) orienta como instal√°-las no Windows, Mac e Linux e foi tamb√©m a base para esse projeto. 
  
  Para o Linux e Mac, os seguintes passos [desse site](https://www.vultr.com/docs/install-apache-spark-on-ubuntu-20-04/?utm_source=performance-max-latam&utm_medium=paidmedia&obility_id=17096555207&utm_adgroup=&utm_campaign=&utm_term=&utm_content=&gclid=CjwKCAjwxaanBhBQEiwA84TVXJ_-wFrxQKfGLVBbsUzhulDxIuDdXzyuF6gKLw5UVoPJeG94eaU0wRoCcuMQAvD_BwE) podem ser √∫teis.

  Um ponto de aten√ß√£o √© que no momento de cria√ß√£o desse reposit√≥rio a vers√£o mais recente do Spark compat√≠vel com o .NET era a **3.2.1** (que foi a usada aqui). 

  Tamb√©m foram utilizadas a **vers√£o 6.0 do .NET** e **2.1.1 do .NET on Spark**.

  No reposit√≥rio oficial do .NET no Spark ([link aqui](https://github.com/dotnet/spark/tree/main/docs/release-notes)) √© poss√≠vel verificar a compatibilidade para efetuar corretamente as instala√ß√µes dos componentes necess√°rios.

---

  <br/>
</details>


<details>
  <summary><strong>Como executar o c√≥digo</strong></summary><br />

  Com as instala√ß√µes feitas e o clone desse reposit√≥rio, siga os seguintes passos:
  
  1¬∫ Navegue via seu terminal at√© a pasta clonada e abra o diret√≥rio **dotnet-on-spark**. Dentro do diret√≥rio execute o seguinte comando:

  ```csharpe
  dotnet new console -o FlowOfCash
  ```

  Caso tenha sucesso, deve ser criado o diret√≥rio **FlowOfCash**.

  2¬∫ Da pasta [**Code**](Code) copie o arquivo **_Program.cs_** e substitua o criado no diret√≥rio **FlowOfCash**.

  3¬∫ Dentro do diret√≥rio **FlowOfCash**. execute os seguintes comandos em ordem:

  ```csharpe
  dotnet add package Microsoft.Spark
  dotnet build
  ```

  Se executado com √™xito, o diret√≥rio **bin** deve ser criado.

  4¬∫ Navegue at√© o arquivo de execu√ß√£o criado atrav√©s do seguinte comando:

  ```bash
  cd bin/Debug/net6.0 
  ```

  Sendo net6.0 a vers√£o utilizada nesse projeto. Caso tenha uma vers√£o diferente em sua m√°quina substitua o comando por ela.

  5¬∫ Dentro da pasta, execute o seguinte comando no terminal:

  ```spark
  spark-submit \ 
  --class org.apache.spark.deploy.dotnet.DotnetRunner \
  --master local \
  microsoft-spark-3-2_2.12-2.1.1.jar \
  dotnet FlowOfCash.dll <caminho-do-clone-do-repositorio/dotnet-on-spark/sample-generator/data/cash_flow.parquet

  ```

  Sendo **_microsoft-spark-3-2_2.12-2.1.1.jar_** a vers√£o compat√≠vel do Spark com Microsoft.Spark.Worker utilizada. 
  
  Considere alterar essa parte do comando caso necess√°rio bem como o caminho do clone do reposit√≥rio para informar o arquivo parquet corretamente.

  Caso executado com √™xito deve ser poss√≠vel visualizar os seguintes resultados:

  * O conte√∫do do arquivo parquet;
  * O tratamento feito √† partir dos dados do arquivo;
  * O √∫ltimo valor da coluna de caixa acumulado (**accumulated_cash**).

</details>


<details>
  <summary><strong>Pr√≥ximos passos</strong></summary><br />

  Por se tratar de um primeiro contato com o .NET on spark e tendo objetivo de registrar os estudos a respeito dele, alguns pontos fundamentais ser√£o revisitados nesse c√≥digo:

  * **Defini√ß√£o de padr√£o de projeto** para desaclopar o c√≥digo executor da leitura e transforma√ß√£o dos arquivos;

  * **Testes unit√°rios** para garantir o design e confiabilidade do c√≥digo constru√≠do;

  * **Utiliza√ß√£o de outras APIs do Spark no contexto do .NET**, para revisitar a linguagem e explorar solu√ß√µes de machine learning, integra√ß√£o com spark sql, etc...

  Caso tenha interesse, considere clonar e ajudar a construirmos juntos esses conhecimentos.

</details>

---
