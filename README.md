# **Boas vindas ao Flow of Cash!**

Para executar o script observe as orienta√ß√µes descritas a seguir e se tiver qualquer d√∫vida, sugest√£o, contribui√ß√£o, considere abrir uma issue ou entrar em contato. üöÄ

O objetivo √© testar o .NET no Apache Spark atrav√©s de um aplicativo de console, com um exemplo de leitura e tratamento simples de arquivo parquet utilizando o C# como linguagem.


# Orienta√ß√µes


<details>
  <summary><strong>Estrutura das pastas</strong></summary><br />

  O diret√≥rio [**Code**](Code) tem um arquivo com o exemplo das depend√™ncias necess√°rias (arquivo FlowOfCash.csproj) e c√≥digo do tratamento do arquivo parquet (arquivo Program.cs) que √© utilizado na execu√ß√£o da aplica√ß√£o.

  E o diret√≥rio [**sample-generator**](sample-generator) tem o c√≥digo python utilizado para cria√ß√£o dos arquivos parquet usados como exemplo, bem como a amostra em si.

  Por ser uma solu√ß√£o de big data, sinta-se √° vontade para alterar o tamanho do sample √† partir do c√≥digo, para explorar o Spark agregado ao .NET.

---

  <br/>
</details>



<details>
  <summary><strong>Pr√© requisitos</strong></summary><br />

  O ambiente para execu√ß√£o do c√≥digo requer as seguintes ferramentas:

  * **.Net**

  * **Java**

  * **Apache Spark**

  * **Microsoft.Spark.Worker**

  [Essa documenta√ß√£o](https://learn.microsoft.com/pt-br/previous-versions/dotnet/spark/tutorials/get-started?tabs=linux&WT.mc_id=dotnet-35129-website) orienta como instal√°-las no Windows, Mac e Linux e foi tamb√©m a base para esse projeto. 
  
  Para uso do Apache Spark no Linux e Mac, os seguintes passos [desse site](https://www.vultr.com/docs/install-apache-spark-on-ubuntu-20-04/?utm_source=performance-max-latam&utm_medium=paidmedia&obility_id=17096555207&utm_adgroup=&utm_campaign=&utm_term=&utm_content=&gclid=CjwKCAjwxaanBhBQEiwA84TVXJ_-wFrxQKfGLVBbsUzhulDxIuDdXzyuF6gKLw5UVoPJeG94eaU0wRoCcuMQAvD_BwE)podem ser √∫teis, tamb√©m os [arquivos de distribui√ß√£o dispon√≠veis](https://archive.apache.org/dist/spark/)

  Um ponto de aten√ß√£o √© que no momento de cria√ß√£o desse reposit√≥rio a vers√£o mais recente do Spark compat√≠vel com o .NET foi a **3.2.1** (que √© usada aqui). 

  Tamb√©m foram utilizadas a **vers√£o 6.0 do .NET** e **2.1.1 do .NET on Spark**.

  No reposit√≥rio oficial do .NET no Spark ([link aqui](https://github.com/dotnet/spark/tree/main/docs/release-notes)) √© poss√≠vel verificar a compatibilidade entre as depend√™ncias para efetuar corretamente as instala√ß√µes dos componentes necess√°rios.

---

  <br/>
</details>

<details>
  <summary><strong>(Opcional) Modificando o sample</strong></summary><br />

  Com o python e o pip instalado, entre no diret√≥rio [**sample-generator**](sample-generator) e siga os seguintes passos:
  
  1¬∫ (Recomendado) Crie um ambiente virtual do python para isolar a execu√ß√£o do projeto das depend√™ncias da sua m√°quina:

  ```bash
  python3 -m venv sample-generator
  source sample-generator/bin/activate
  ```

  Caso tenha sucesso, deve ser criado o diret√≥rio **sample-generator**.

  2¬∫ Instale as depend√™ncias do script python com o comando:

  ```bash
  pip install -r requirements.txt
  ```

  3¬∫ (Opcional) Para alterar a quantidade de registros a serem gerados, modifique o valor da linha 49 do arquivo `generator.py` como demonstrado na imagem abaixo:


  ### **Imagem 01 - Alterando a quantidade de registros do arquivo parquet.**
  <img alt="generator.py" src="utils/images/image.png">

  4¬∫ Com os passos anteriores, execute o comando para gerar os arquivos parquet:

  ```bash
  python generator.py
  ```


</details>

<details>
  <summary><strong>Como executar o c√≥digo</strong></summary><br />

  Com as instala√ß√µes dos pr√© requisitos feitas e o clone desse reposit√≥rio, siga os seguintes passos:
  
  1¬∫ Navegue via seu terminal at√© a pasta clonada e abra o diret√≥rio **dotnet-on-spark**. Dentro do diret√≥rio execute o seguinte comando:

  ```csharpe
  dotnet new console -o FlowOfCash
  ```

  Caso tenha sucesso, deve ser criado o diret√≥rio **FlowOfCash**.

  2¬∫ Da pasta [**Code**](Code) copie o arquivo **_Program.cs_** e substitua o criado no diret√≥rio **FlowOfCash**.

  3¬∫ Dentro do diret√≥rio **FlowOfCash**. execute os seguintes comandos em ordem:

  ```csharpe
  dotnet add package Microsoft.Spark
  dotnet build
  ```

  Se executado com √™xito, o diret√≥rio **bin** deve ser criado.

  4¬∫ Navegue at√© o arquivo de execu√ß√£o criado atrav√©s do seguinte comando:

  ```bash
  cd bin/Debug/net6.0 
  ```

  Sendo net6.0 a vers√£o utilizada nesse projeto. Caso tenha uma vers√£o diferente em sua m√°quina substitua o valor da vers√£o pela correspondente.

  5¬∫ Dentro da pasta, execute o seguinte comando no terminal:

  ```spark
spark-submit \
--class org.apache.spark.deploy.dotnet.DotnetRunner \
--master local \
microsoft-spark-3-2_2.12-2.1.1.jar \
dotnet FlowOfCash.dll <caminho-do-clone-do-repositorio/dotnet-on-spark/sample-generator/data/cash_flow.parquet

  ```

  Sendo **_microsoft-spark-3-2_2.12-2.1.1.jar_** a vers√£o compat√≠vel do Spark com Microsoft.Spark.Worker utilizada. Caso use uma vers√£o do Spark 3.1.2 altere para a vers√£o compat√≠vel do worker.
  
  Tamb√©m substitua o in√≠cio do caminho do diret√≥rio do arquivo parquet pelo caminho do clone do reposit√≥rio.

  Caso executado com √™xito deve ser poss√≠vel visualizar os seguintes resultados:

  * O conte√∫do do arquivo parquet;
  * O tratamento feito √† partir dos dados do arquivo;
  * O √∫ltimo valor da coluna de caixa acumulado (**accumulated_cash**).

</details>


<details>
  <summary><strong>Pr√≥ximos passos</strong></summary><br />

  Por se tratar de um primeiro contato com o .NET on spark e tendo objetivo de registrar os estudos a respeito dele, alguns pontos fundamentais ser√£o revisitados nesse c√≥digo:

  * **Defini√ß√£o de padr√£o de projeto** para desaclopar o c√≥digo executor da leitura e transforma√ß√£o dos arquivos;

  * **Testes unit√°rios** para garantir o design e confiabilidade do c√≥digo constru√≠do;

  * **Utiliza√ß√£o de outras APIs do Spark no contexto do .NET**, para revisitar a linguagem e explorar solu√ß√µes de machine learning, integra√ß√£o com spark sql, etc...

  Caso tenha interesse, considere clonar e ajudar a explorar essa solu√ß√£o.

</details>

---
